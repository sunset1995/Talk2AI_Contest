{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding via word2vec\n",
    "- [NLP 學習筆記](https://hackmd.io/Gw4TgIwEwhaAGYAzOAWKBWYtIYMyxbICGeUATMAKbFRA)\n",
    "- [以 gensim 訓練中文詞向量](http://zake7749.github.io/2016/08/28/word2vec-with-gensim/)\n",
    "- [tfidf 關鍵字擷取](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer)\n",
    "- [On word embeddings](http://ruder.io/secret-word2vec/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract training datas\n",
    "sentences = word2vec.Text8Corpus('datas/wiki-seg.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show one tokenize \"sentence\"\n",
    "for i, s in enumerate(sentences):\n",
    "    print('')\n",
    "    print(s)\n",
    "    print('=' * 100)\n",
    "    if i >= 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train word2vec model\n",
    "\n",
    "# !! Warning !!\n",
    "# Below code will run roughly 30 minutes\n",
    "\n",
    "# Uncomment to train again\n",
    "# word2vec_model = word2vec.Word2Vec(sentences, size=250, workers=4)\n",
    "# word2vec_model.total_train_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !! Warning !!\n",
    "# Below code will replace original result\n",
    "\n",
    "# word2vec_model.save('models/word2vec_500.model.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### jieba 分詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "jieba.set_dictionary('datas/dict/dict.txt.big')\n",
    "jieba.load_userdict('datas/dict/edu_dict.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba.analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "setence = '美國總統川普發表「烈焰怒火」言論，誓言如果北韓不停手，就施以世人前所未見的猛烈攻擊。關島政府急急在翌日發表聲明，呼籲民眾和遊客冷靜、不用恐慌，當地並沒有即時危險。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.analyse.tfidf(setence, topK=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.analyse.textrank(setence, topK=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec_model = word2vec.Word2Vec.load('models/word2vec_250.model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numbers of words in dictionary\n",
    "len(word2vec_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word2vec_model.wv.similarity('男朋友', '可愛'))\n",
    "print(word2vec_model.wv.similarity('女朋友', '可愛'))\n",
    "print(word2vec_model.wv.similarity('皮卡丘', '可愛'))\n",
    "print(word2vec_model.wv.similarity('愛因斯坦', '可愛'))\n",
    "print(word2vec_model.wv.similarity('傅立葉', '可愛'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model.wv.most_similar(positive=['國王', '女'], negative=['男'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model.wv.most_similar('皮卡丘', topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine similarity between two set of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [['光電效應'], ['高斯分佈'], ['電'], ['原子彈'], ['可愛'], ['革命']]\n",
    "options = ('皮卡丘', '愛因斯坦', '小智', '傅立葉', '孫文', '高斯', '女朋友')\n",
    "for question in questions:\n",
    "    print('Questions', question)\n",
    "    scores = []\n",
    "    for option in options:\n",
    "        scores.append((word2vec_model.wv.n_similarity(question, [option]), option))\n",
    "    scores.sort(reverse=True)\n",
    "    for _ in scores:\n",
    "        print('%15.4f (%s)' % (_[0], _[1]))\n",
    "    print('=' * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Mover's Distance between two documents/sentences\n",
    "- [A Linear Time Histogram Metric for Improved SIFT Matching](http://www.cs.huji.ac.il/~werman/Papers/ECCV2008.pdf)\n",
    "- [Fast and Robust Earth Mover’s Distances](http://www.cs.huji.ac.il/~werman/Papers/ICCV2009.pdf)\n",
    "- [From Word Embeddings To Document Distances](http://proceedings.mlr.press/v37/kusnerb15.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    '蘋果從樹上掉下來',\n",
    "    '從直升機上跳下來',\n",
    "    '蘋果是長在樹上的',\n",
    "]\n",
    "for i in range(len(sentences)):\n",
    "    sentences[i] = list(jieba.cut(sentences[i]))\n",
    "for i in range(len(sentences)):\n",
    "    for j in range(i+1, len(sentences)):\n",
    "        s1 = sentences[i]\n",
    "        s2 = sentences[j]\n",
    "        print('%-35s vs. %-35s => %f' % (s1, s2, word2vec_model.wv.wmdistance(s1, s2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find most doesn't match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model.wv.doesnt_match(['早餐', '午餐', '美食', '電視', '晚餐'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict center word probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model.predict_output_word(list(jieba.cut('警察在深夜攻堅敵人總部')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model.wv.similarity('憫惻', '哀憐')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model.wv.similarity('可愛', '可惡')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model.wv.similarity('可憎', '可愛')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
