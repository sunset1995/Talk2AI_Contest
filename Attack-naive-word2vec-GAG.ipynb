{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# naive word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /Users/sunset/Talk2AI_Contest/datas/dict/dict.txt.big ...\n",
      "Loading model from cache /var/folders/43/l4vp_w_x4wb11mmy_bb1jrkc0000gn/T/jieba.u857f67a870683287981bc6f5b9493ffc.cache\n",
      "Loading model cost 2.302 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "from scipy import stats\n",
    "\n",
    "# Import & Init jieba\n",
    "import jieba\n",
    "jieba.set_dictionary('datas/dict/dict.txt.big')\n",
    "jieba.load_userdict('datas/dict/edu_dict.txt')\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "# Import util\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv('datas/sample_test_data.txt')\n",
    "x1 = [[s for s in re.sub('[A-Z]:', '\\t', _).split('\\t') if len(s.strip())] for _ in sample.dialogue.values]\n",
    "x2 = [[s for s in re.sub('[A-Z]:', '\\t', _).split('\\t') if len(s.strip())] for _ in sample.options.values]\n",
    "y = sample.answer.values\n",
    "assert(np.sum([len(_)!=6 for _ in x2]) == 0)\n",
    "\n",
    "test_datas = pd.read_csv('datas/AIFirstProblem.txt')\n",
    "test_x1 = [[s for s in re.sub('[A-Z]:', '\\t', _).split('\\t') if len(s.strip())] for _ in test_datas.dialogue.values]\n",
    "test_x2 = [[s for s in re.sub('[A-Z]:', '\\t', _).split('\\t') if len(s.strip())] for _ in test_datas.options.values]\n",
    "assert(np.sum([len(_)!=6 for _ in test_x2]) == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5909"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format('models/word2vec/language-model-1.txt', binary=False)\n",
    "len(word_vectors.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unk_cnt = 0\n",
    "for a, b in zip(x1, x2):\n",
    "    a_sentence = [ch for s in a for ch in s if ch.strip() != '']\n",
    "    b_sentences = [[ch for ch in rs if ch.strip() != ''] for rs in b]\n",
    "    \n",
    "    unk_cnt += len([ch for ch in a_sentence if ch not in word_vectors.vocab])\n",
    "    unk_cnt += len([ch for s in b_sentences for ch in s if ch not in word_vectors.vocab])\n",
    "unk_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Naive trial - centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def unitvec(vec):\n",
    "    l = np.linalg.norm(vec)\n",
    "    return vec / l if l != 0 else vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def centroid(sentence):\n",
    "    _ = [word_vectors.word_vec(word) for word in sentence if word in word_vectors.vocab]\n",
    "    return np.mean(_, axis=0) if len(_) > 0 else np.zeros(word_vectors.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def attack_naive_centroid(x1, x2):\n",
    "    my_cos_ans = []\n",
    "    my_dot_ans = []\n",
    "    for a, b in zip(x1, x2):\n",
    "        a_sentence = [ch for s in a for ch in s if ch.strip() != '']\n",
    "        b_sentences = [[ch for ch in rs if ch.strip() != ''] for rs in b]\n",
    "\n",
    "        a_center = centroid(a_sentence)\n",
    "        b_centers = [centroid(s) for s in b_sentences]\n",
    "\n",
    "        score = [np.dot(unitvec(a_center), unitvec(bc)) for bc in b_centers]\n",
    "        my_cos_ans.append(np.argmax(score))\n",
    "        \n",
    "        score = [np.dot(a_center, bc) for bc in b_centers]\n",
    "        my_dot_ans.append(np.argmax(score))\n",
    "    return np.array(my_cos_ans), np.array(my_dot_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      centroid (cos):  26 /  50\n",
      "      centroid (dot):  22 /  50\n"
     ]
    }
   ],
   "source": [
    "cos_ans, dot_ans = attack_naive_centroid(x1, x2)\n",
    "\n",
    "correct = np.sum(cos_ans == y)\n",
    "print('%20s: %3d / %3d' % ('centroid (cos)', correct, len(y)))\n",
    "\n",
    "correct = np.sum(dot_ans == y)\n",
    "print('%20s: %3d / %3d' % ('centroid (dot)', correct, len(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Output answer on testing datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "my_test_ans, _ = attack_naive_centroid(test_x1, test_x2)\n",
    "# my_test_ans = stats.mode(test_ans_bag).mode[0]\n",
    "# my_test_ans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# with open('answer/attack-naive-word2vec-fine-tune-6-not-yet.txt', 'w') as fo:\n",
    "#     fo.write('id,ans\\n')\n",
    "#     fo.write('\\n'.join(['%d,%s' % (i+1, ans) for i, ans in enumerate(my_test_ans)]))\n",
    "#     fo.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
