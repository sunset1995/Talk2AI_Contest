{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-batchizer\n",
    "train 資料可能很大，跑 Mini-batch 時應該儘量不增加記憶體使用量 (用 reference 的)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "# Import util\n",
    "import time\n",
    "import re\n",
    "import sys\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 資料 scenario：一個問題 n 個選項"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class mini_batcher_one_q_multiple_r():\n",
    "    def __init__(self, x1, x2, y):\n",
    "        '''\n",
    "        Parameters\n",
    "            x1: np.array. Containing a list of questions\n",
    "            x2: np.array. Containing options for each corresponding x1(question)\n",
    "            y : np.array. Containing a list of int which is the answer for corresponding x1(question)\n",
    "        Note I:\n",
    "            x1, x2, y inside or outside the class are referencing to same memory.\n",
    "            So do all returning result by this class.\n",
    "            This class won't (hope) do any modification on x1, x2, y\n",
    "        Note II:\n",
    "            # of batch in a epoch for sigmoid = # of options\n",
    "            # of batch in a epoch for cross entropy = # of questions\n",
    "        '''\n",
    "        if type(x1) != np.ndarray or type(x2) != np.ndarray or type(y) != np.ndarray:\n",
    "            raise AssertionError('x1, x2, y should be np.ndarray')\n",
    "        if len(x1) != len(x2) or len(x1) != len(y):\n",
    "            raise AssertionError('len(x1), len(x2), len(y) should be the same')\n",
    "        for i in range(len(x2)):\n",
    "            if len(x2[i]) != len(x2[0]):\n",
    "                raise AssertionError('Each element of x2 should be the same length')\n",
    "        self._x1 = x1\n",
    "        self._x2 = x2\n",
    "        self._y = y\n",
    "        self._sigmoid_pointer = 0\n",
    "        self._sigmoid_idx_pool = np.array([(i, j) for i in range(len(x2)) for j in range(len(x2[i]))])\n",
    "        self._entropy_pointer = 0\n",
    "        self._entropy_idx_pool = np.arange(len(x1))\n",
    "        np.random.shuffle(self._sigmoid_idx_pool)\n",
    "        np.random.shuffle(self._entropy_idx_pool)\n",
    "\n",
    "\n",
    "    def next_batch_4_sigmoid(self, batch_size):\n",
    "        f = self._sigmoid_pointer\n",
    "        t = self._sigmoid_pointer + batch_size\n",
    "        if t > len(self._sigmoid_idx_pool):\n",
    "            f = 0\n",
    "            t = batch_size\n",
    "            np.random.shuffle(self._sigmoid_idx_pool)\n",
    "        self._sigmoid_pointer = t\n",
    "        idx = self._sigmoid_idx_pool[f:t]\n",
    "        idx_0 = idx[:, 0]\n",
    "        idx_1 = idx[:, 1]\n",
    "        return self._x1[idx_0], self._x2[idx_0, idx_1], np.array(self._y[idx_0]==idx_1, dtype=np.int8)\n",
    "\n",
    "\n",
    "    def next_batch_4_cross_entropy(self, batch_size):\n",
    "        f = self._entropy_pointer\n",
    "        t = self._entropy_pointer + batch_size\n",
    "        if t > len(self._entropy_idx_pool):\n",
    "            f = 0\n",
    "            t = batch_size\n",
    "            np.random.shuffle(self._entropy_idx_pool)\n",
    "        self._entropy_pointer = t\n",
    "        idx = self._entropy_idx_pool[f:t]\n",
    "        onehot = np.zeros((len(idx), len(x2[0])))\n",
    "        onehot[np.arange(len(idx)), self._y[idx]] = 1\n",
    "        return self._x1[idx], self._x2[idx], onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Datas for Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv('datas/sample_test_data.txt')\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract sample test datas\n",
    "x1 = np.array(\n",
    "    [[s for s in re.sub('[A-Z]:', '\\t', _).split('\\t') if len(s.strip())] for _ in sample.dialogue.values]\n",
    ")\n",
    "x2 = np.array(\n",
    "    [[s for s in re.sub('[A-Z]:', '\\t', _).split('\\t') if len(s.strip())] for _ in sample.options.values]\n",
    ")\n",
    "y = np.array(sample.answer.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(x1[27])\n",
    "print(x2[27])\n",
    "print(y[27])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sigmoid scenario\n",
    "data_loader = mini_batcher_one_q_multiple_r(x1, x2, y)\n",
    "batch_size = 5\n",
    "batch_q, batch_r, batch_ans = data_loader.next_batch_4_sigmoid(batch_size)\n",
    "for i in range(batch_size):\n",
    "    print('  Q:', batch_q[i])\n",
    "    print('  R:', batch_r[i])\n",
    "    print('ans:', batch_ans[i])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross entropy scenario\n",
    "data_loader = mini_batcher_one_q_multiple_r(x1, x2, y)\n",
    "batch_size = 5\n",
    "batch_q, batch_r, batch_ans = data_loader.next_batch_4_cross_entropy(batch_size)\n",
    "for i in range(batch_size):\n",
    "    print('  Q:', batch_q[i])\n",
    "    for j in range(len(batch_r[i])):\n",
    "        print('R%2d: %s' % (j, batch_r[i][j]))\n",
    "    print('ans:', batch_ans[i])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 資料 scenario：多個不同長度的文本，轉成一筆一筆的 (上句, 下句, 0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class mini_batcher_corpus():\n",
    "    def __init__(self, corpus, n_wrong=1):\n",
    "        '''\n",
    "        Parameters:\n",
    "            corpus : list of corpus (2D)\n",
    "            n_wrong: int. # of wrong answer to be generated for each question.\n",
    "        Note I:\n",
    "            This class will create a flatten (1D) version of corpus for convenient.\n",
    "            But still a reference to outside corpus, changing corpus outside will \n",
    "            changing corpus inside the class also.\n",
    "        '''\n",
    "        self._corpus = np.array([s for c in corpus for s in c])\n",
    "        self._pointer = 0\n",
    "        \n",
    "        border_idx = np.cumsum([len(c) for c in corpus]) - 1\n",
    "        que_idx = np.delete(np.arange(np.sum([len(c) for c in corpus])), border_idx)\n",
    "        ans_idx = que_idx + 1\n",
    "        \n",
    "        self._dt_pool = np.vstack([\n",
    "            np.stack([que_idx, ans_idx, np.ones(len(que_idx), dtype=np.int32)], axis=1),\n",
    "            *[\n",
    "                np.stack([que_idx, self.__get_wrong_idx(ans_idx), np.zeros(len(que_idx), dtype=np.int32)], axis=1)\n",
    "                for i in range(n_wrong)\n",
    "            ]\n",
    "        ])\n",
    "        np.random.shuffle(self._dt_pool)\n",
    "        \n",
    "        self.data_num = len(self._dt_pool)\n",
    "\n",
    "\n",
    "    def __get_wrong_idx(self, ans_idx):\n",
    "        '''\n",
    "        Generate a sequence which is a shuffle version of input ans.\n",
    "        Each output elements is different from input ans.\n",
    "        '''\n",
    "        assert(len(ans_idx) > 1)\n",
    "        idx = ans_idx.copy()\n",
    "        np.random.shuffle(idx)\n",
    "        for i in np.where(idx == ans_idx)[0]:\n",
    "            if idx[i] != ans_idx[i]:\n",
    "                continue\n",
    "            t = np.random.randint(len(ans_idx))\n",
    "            while t==i or idx[i]==ans_idx[t] or idx[t]==ans_idx[i]:\n",
    "                t = np.random.randint(len(ans_idx))\n",
    "            idx[i], idx[t] = idx[t], idx[i]\n",
    "        return idx\n",
    "\n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "        f = self._pointer\n",
    "        t = self._pointer + batch_size\n",
    "        if t > self.data_num:\n",
    "            f = 0\n",
    "            t = batch_size\n",
    "            np.random.shuffle(self._dt_pool)\n",
    "        self._pointer = t\n",
    "        dt = self._dt_pool[f:t]\n",
    "        x1 = self._corpus[dt[:, 0]]\n",
    "        x2 = self._corpus[dt[:, 1]]\n",
    "        y = dt[:, 2]\n",
    "        return x1, x2, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('datas/training_data/下課花路米.txt') as f:\n",
    "    corpus = [[s.split() for s in line.split('\\t')] for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = mini_batcher_corpus(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1: ['我們', '正要', '體驗', '傳統', '屋', '的', '一天']\n",
      "x2: ['而且', '我', '跟', '你', '說']\n",
      "y : 1\n",
      "\n",
      "x1: ['特辣', '的', '韓式', '泡菜']\n",
      "x2: ['你', '可以', '試試看']\n",
      "y : 1\n",
      "\n",
      "x1: ['我', '去', '找', '專家', '好不好']\n",
      "x2: ['所以', '本來', '只要', '做', '這麼', '小', '隻', '就', '對', '了']\n",
      "y : 0\n",
      "\n",
      "x1: ['而且', '我', '發現', '到']\n",
      "x2: ['其實', '平常', '很多', '東西']\n",
      "y : 1\n",
      "\n",
      "x1: ['要給', '大家', '欣賞']\n",
      "x2: ['我們', '三個']\n",
      "y : 1\n",
      "\n",
      "x1: ['酵素', '它', '可以', '幫助', '我們', '腸胃', '消化']\n",
      "x2: ['翻修', '成', '現在', '看到', '的', '這個', '模樣', '啦']\n",
      "y : 0\n",
      "\n",
      "x1: ['那', '不過', '這個', '嫁妝']\n",
      "x2: ['對']\n",
      "y : 0\n",
      "\n",
      "x1: ['這種', '東西', '質感', '好壞', '還是', '有差']\n",
      "x2: ['你', '不', '記得', '之前', '小升', '他', '有', '去', '金門']\n",
      "y : 1\n",
      "\n",
      "x1: ['那棵', '嗎']\n",
      "x2: ['這個', '好像', '黃黃', '綠綠的', '還沒開', '耶']\n",
      "y : 0\n",
      "\n",
      "x1: ['好', '用力']\n",
      "x2: ['所以', '說', '使用', '蠟筆', '就', '不會']\n",
      "y : 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "x1, x2, y = data_loader.next_batch(batch_size)\n",
    "for i in range(batch_size):\n",
    "    print('x1:', x1[i])\n",
    "    print('x2:', x2[i])\n",
    "    print('y :', y[i])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
