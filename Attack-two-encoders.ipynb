{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /Users/sunset/Talk2AI_Contest/datas/dict/dict.txt.big ...\n",
      "Loading model from cache /var/folders/43/l4vp_w_x4wb11mmy_bb1jrkc0000gn/T/jieba.u857f67a870683287981bc6f5b9493ffc.cache\n",
      "Loading model cost 2.047 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import jieba\n",
    "jieba.set_dictionary('datas/dict/dict.txt.big')\n",
    "jieba.load_userdict('datas/dict/edu_dict.txt')\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "import json\n",
    "from mini_batch_helper import extractor, MiniBatchCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in  training data\n",
    "word2vec_fname = 'models/word2vec/fine-tuned-2.txt'\n",
    "corpus_fnames = [\n",
    "    'datas/training_data/下課花路米.txt',\n",
    "    'datas/training_data/人生劇展.txt',\n",
    "    'datas/training_data/公視藝文大道.txt',\n",
    "    'datas/training_data/成語賽恩思.txt',\n",
    "    'datas/training_data/我的這一班.txt',\n",
    "    'datas/training_data/流言追追追.txt',\n",
    "    'datas/training_data/聽聽看.txt',\n",
    "    'datas/training_data/誰來晚餐.txt',\n",
    "]\n",
    "sample_rate_on_training_datas = 1.0  # 1.0\n",
    "extra_words = ['<pad>']\n",
    "unknown_word = None\n",
    "\n",
    "word2id, id2word, word_p, embedding_matrix, corpus, corpus_id = extractor(word2vec_fname, corpus_fnames, sample_rate_on_training_datas, extra_words, unknown_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train datas num: 5778416\n",
      "valid datas num: 16912\n"
     ]
    }
   ],
   "source": [
    "# Data split\n",
    "rnd_idx = np.arange(len(corpus_id))\n",
    "np.random.shuffle(rnd_idx)\n",
    "corpus_id = corpus_id[rnd_idx[:len(corpus_id)]]\n",
    "valid_corpus_num = 10\n",
    "\n",
    "train_data_loader = MiniBatchCorpus(corpus_id[valid_corpus_num:])\n",
    "valid_data_loader = MiniBatchCorpus(corpus_id[:valid_corpus_num])\n",
    "print('train datas num:', train_data_loader.data_num, flush=True)\n",
    "print('valid datas num:', valid_data_loader.data_num, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len = max([len(sentence) for episode in corpus_id for sentence in episode])\n",
    "max_seq_len\n",
    "\n",
    "del(corpus)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# reference: https://github.com/dennybritz/chatbot-retrieval/blob/8b1be4c2e63631b1180b97ef927dc2c1f7fe9bea/udc_hparams.py\n",
    "exp_name = 'two_encoders_?'\n",
    "# Model Parameters\n",
    "params = {}\n",
    "save_params_dir = 'models/%s/' %exp_name\n",
    "params['word2vec_model_name'] = word2vec_fname\n",
    "params['word2vec_vocab_size'] = embedding_matrix.shape[0]\n",
    "params['word2vec_dim'] = embedding_matrix.shape[1]\n",
    "params['rnn_dim'] = 256  # 256, 384, 512\n",
    "params['n_layers'] = 4\n",
    "params['forget_bias'] = 1.0\n",
    "\n",
    "# Training Parameters\n",
    "params['learning_rate'] = 1e-4\n",
    "params['keep_prob_train'] = 0.8 # 0.5\n",
    "params['keep_prob_valid'] = 1.0\n",
    "params['l1_loss'] = 1e-4 #1e-6 # regularize M\n",
    "params['clip'] = 1  # 1e-2\n",
    "params['batch_size'] = 256 #512\n",
    "params['eval_batch_size'] = 16\n",
    "params['n_iterations'] = int(20 * train_data_loader.data_num / params['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(save_params_dir):\n",
    "    os.makedirs(save_params_dir)\n",
    "with open(save_params_dir+'model_parameters.json', 'w') as f:\n",
    "    json.dump(params, f, indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "record = {}\n",
    "save_record_dir = 'models/%s/' %exp_name\n",
    "record['newest_model_dir'] = 'models/' + exp_name +'/newest/'\n",
    "record['best_model_dir'] = 'models/' + exp_name +'/best/'\n",
    "record['loss_train'] = []\n",
    "record['loss_valid'] = []\n",
    "record['accuracy_valid'] = []\n",
    "record['best_iter'] = 0\n",
    "record['sample_correct'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "import tensorflow as tf\n",
    "\n",
    "# Input\n",
    "context = tf.placeholder(dtype=tf.int32, shape=(None, None), name='context')\n",
    "context_len = tf.placeholder(dtype=tf.int32, shape=(None,), name='context_len')\n",
    "response = tf.placeholder(dtype=tf.int32, shape=(None, None), name='response')\n",
    "response_len = tf.placeholder(dtype=tf.int32, shape=(None,), name='response_len')\n",
    "#target = tf.placeholder(dtype=tf.float32, shape=(None, ), name='target')\n",
    "target = tf.placeholder(dtype=tf.int32, shape=(None, ), name='target')\n",
    "keep_prob = tf.placeholder(dtype=tf.float32, name='keep_prob')\n",
    "\n",
    "\n",
    "#with tf.device('/gpu:0'):\n",
    "# Embedding\n",
    "init_embedding_W = tf.constant_initializer(embedding_matrix)\n",
    "embeddings_W = tf.get_variable('embeddings_W', shape=[embedding_matrix.shape[0], embedding_matrix.shape[1]], initializer=init_embedding_W)\n",
    "context_embedded = tf.nn.embedding_lookup(embeddings_W, context, name=\"embed_context\")\n",
    "response_embedded = tf.nn.embedding_lookup(embeddings_W, response, name=\"embed_response\")\n",
    "\n",
    "if params['n_layers'] == 1:\n",
    "    with tf.variable_scope('context'):\n",
    "        c_cell = tf.nn.rnn_cell.LSTMCell(num_units=params['rnn_dim'], forget_bias=params['forget_bias'], \n",
    "                    use_peepholes=True, state_is_tuple=True)\n",
    "        c_cell = tf.contrib.rnn.DropoutWrapper(c_cell, input_keep_prob=keep_prob, output_keep_prob=keep_prob)\n",
    "        c_outputs, c_states = tf.nn.dynamic_rnn(c_cell, context_embedded, sequence_length=context_len, dtype=tf.float32)\n",
    "        encoding_context = c_states.h\n",
    "    \n",
    "    with tf.variable_scope('response'):\n",
    "        r_cell = tf.nn.rnn_cell.LSTMCell(num_units=params['rnn_dim'], forget_bias=params['forget_bias'], \n",
    "                    use_peepholes=True, state_is_tuple=True)\n",
    "        r_cell = tf.contrib.rnn.DropoutWrapper(r_cell, input_keep_prob=keep_prob, output_keep_prob=keep_prob)\n",
    "        r_outputs, r_states = tf.nn.dynamic_rnn(r_cell, response_embedded, sequence_length=response_len, dtype=tf.float32)\n",
    "        encoding_response = r_states.h\n",
    "else:\n",
    "    with tf.variable_scope('context') as scope:\n",
    "        c_cells = [tf.nn.rnn_cell.LSTMCell(num_units=params['rnn_dim'], forget_bias=params['forget_bias'], use_peepholes=True, state_is_tuple=True, reuse=tf.get_variable_scope().reuse) \n",
    "                    for _ in range(params['n_layers'])]\n",
    "        c_dropcells = [tf.contrib.rnn.DropoutWrapper(cell,input_keep_prob=keep_prob) for cell in c_cells]\n",
    "        c_multicell = tf.contrib.rnn.MultiRNNCell(c_dropcells, state_is_tuple=True)\n",
    "        c_multicell = tf.contrib.rnn.DropoutWrapper(c_multicell, output_keep_prob=keep_prob)\n",
    "        c_outputs, c_states = tf.nn.dynamic_rnn(c_multicell, context_embedded, sequence_length=context_len, dtype=tf.float32)\n",
    "        encoding_context = c_states[-1].h\n",
    "    \n",
    "    with tf.variable_scope('response') as scope:\n",
    "        r_cells = [tf.nn.rnn_cell.LSTMCell(num_units=params['rnn_dim'], forget_bias=params['forget_bias'], use_peepholes=True, state_is_tuple=True, reuse=tf.get_variable_scope().reuse) \n",
    "                    for _ in range(params['n_layers'])]\n",
    "        r_dropcells = [tf.contrib.rnn.DropoutWrapper(cell,input_keep_prob=keep_prob) for cell in r_cells]\n",
    "        r_multicell = tf.contrib.rnn.MultiRNNCell(r_dropcells, state_is_tuple=True)\n",
    "        r_multicell = tf.contrib.rnn.DropoutWrapper(r_multicell, output_keep_prob=keep_prob)\n",
    "        r_outputs, r_states = tf.nn.dynamic_rnn(r_multicell, response_embedded, sequence_length=response_len, dtype=tf.float32)\n",
    "        encoding_response = r_states[-1].h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Cosine Similarity\n",
    "# cos_sim = tf.reduce_sum(tf.multiply(tf.nn.l2_normalize(encoding_context,1), tf.nn.l2_normalize(encoding_response,1)), axis=1)\n",
    "\n",
    "#cos_sim = tf.multiply(encoding_context, encoding_response)  # None, 512\n",
    "#cos_sim = tf.reduce_sum(cos_sim, axis=1)  # None\n",
    "#cos_sim = cos_sim / (tf.norm(encoding_context, axis=1)*tf.norm(encoding_response, axis=1))  # None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Sigmoid cross-entropy loss\\ntarget_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=cos_sim, labels=tf.to_float(target)))\\nloss = target_loss\\n\\n# Accuracy\\ncorrect_prediction = tf.logical_or( tf.logical_and(tf.equal(target,1), tf.greater_equal(tf.log_sigmoid(cos_sim), 0.5)), tf.logical_and(tf.equal(target, 0), tf.less(tf.log_sigmoid(cos_sim), 0.5)))\\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Loss: Sigmoid of cosine similarity '''\n",
    "'''\n",
    "# Sigmoid cross-entropy loss\n",
    "target_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=cos_sim, labels=tf.to_float(target)))\n",
    "loss = target_loss\n",
    "\n",
    "# Accuracy\n",
    "correct_prediction = tf.logical_or( tf.logical_and(tf.equal(target,1), tf.greater_equal(tf.log_sigmoid(cos_sim), 0.5)), tf.logical_and(tf.equal(target, 0), tf.less(tf.log_sigmoid(cos_sim), 0.5)))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "''' Loss: cMr '''\n",
    "# σ(cMr)\n",
    "M = tf.get_variable('M', shape=[params['rnn_dim'], params['rnn_dim']], initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "\n",
    "# \"Predict\" a  response: c * M\n",
    "generated_response = tf.matmul(encoding_context, M)\n",
    "generated_response = tf.expand_dims(generated_response, 2)\n",
    "encoding_response = tf.expand_dims(encoding_response, 2)\n",
    "\n",
    "# Dot product between generated response and actual response\n",
    "logits = tf.matmul(generated_response, encoding_response, True)\n",
    "logits = tf.reshape(logits, [-1])\n",
    "\n",
    "# Apply sigmoid to convert logits to probabilities (for prediction, not for loss)\n",
    "probs = tf.sigmoid(logits)\n",
    "correct_prediction = tf.logical_or( tf.logical_and(tf.equal(target,1), tf.greater_equal(probs,0.5)), tf.logical_and(tf.equal(target,0), tf.less(probs,0.5)))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "# Calculate the binary cross-entropy loss\n",
    "target_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=tf.to_float(target)))\n",
    "l1_loss = params['l1_loss'] * tf.reduce_sum(tf.abs(M))\n",
    "loss = target_loss + l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Accuracy\\ncorrect_prediction = tf.logical_or( tf.logical_and(tf.equal(target,1), tf.greater_equal(cos_sim, 0.5)), tf.logical_and(tf.equal(target, 0), tf.less(cos_sim, 0.5)))\\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\\n\\n# Cosine Similarity cross-entropy Loss \\ntarget_loss = tf.multiply(tf.to_float(target), -tf.log(cos_sim)) + tf.multiply(1-tf.to_float(target), -tf.log(1-cos_sim))\\ntarget_loss = tf.reduce_mean(target_loss)\\nloss = target_loss\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Loss: Cosine Similarity '''\n",
    "'''\n",
    "# Accuracy\n",
    "correct_prediction = tf.logical_or( tf.logical_and(tf.equal(target,1), tf.greater_equal(cos_sim, 0.5)), tf.logical_and(tf.equal(target, 0), tf.less(cos_sim, 0.5)))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Cosine Similarity cross-entropy Loss \n",
    "target_loss = tf.multiply(tf.to_float(target), -tf.log(cos_sim)) + tf.multiply(1-tf.to_float(target), -tf.log(1-cos_sim))\n",
    "target_loss = tf.reduce_mean(target_loss)\n",
    "loss = target_loss\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Train step\n",
    "optimizer = tf.train.AdamOptimizer(params['learning_rate'])\n",
    "gvs = optimizer.compute_gradients(loss)\n",
    "capped_gvs = [(tf.clip_by_norm(grad, params['clip']), var) for grad, var in gvs]\n",
    "train_step = optimizer.apply_gradients(capped_gvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_valid_loss_accuracy(sess):\n",
    "    valid_loss = 0\n",
    "    valid_accuracy = 0\n",
    "    n_iter = int(valid_data_loader.data_num/params['batch_size'])\n",
    "    for iter in range(n_iter):\n",
    "        next_x1, next_x2, next_y, x1_len, x2_len = valid_data_loader.next_batch(batch_size=params['batch_size'], pad_to_length=max_seq_len, pad_word=word2id['<pad>'], return_len=True)\n",
    "        new_accuracy, new_loss = sess.run([accuracy, loss], \n",
    "                                    feed_dict={context: next_x1, response: next_x2, target: next_y, \n",
    "                                    keep_prob: params['keep_prob_train'], context_len: x1_len, response_len:x2_len}) \n",
    "        valid_accuracy += new_accuracy\n",
    "        valid_loss += new_loss\n",
    "    valid_loss /= n_iter\n",
    "    valid_accuracy /= n_iter\n",
    "    print('Valid loss = %.5f, accuracy = %.5f' % (valid_loss, valid_accuracy), flush=True)\n",
    "    record['loss_valid'].append( valid_loss.tolist() )\n",
    "    record['accuracy_valid'].append( valid_accuracy.tolist() )\n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations    1:\tloss = 0.69315 / L1 = 0.04728 / elapsed time 17\n",
      "Valid loss = 0.73978, accuracy = 0.50000\n",
      "Best model save in 0 iteration\n",
      "Iterations    2:\t"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-e1e3c38bcd4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         batch_loss, batch_l1_loss, _ = sess.run([target_loss, l1_loss, train_step], \n\u001b[1;32m     17\u001b[0m                             feed_dict={context: next_x1, response: next_x2, target: next_y, \n\u001b[0;32m---> 18\u001b[0;31m                             keep_prob: params['keep_prob_train'], context_len: x1_len, response_len:x2_len}) \n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss = %.5f / L1 = %.5f / elapsed time %.f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_l1_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "start_time = time.time()\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Restore model\n",
    "    # saver.restore(sess, record['best_model_dir']+'model.ckpt')\n",
    "    # print('Retrain model: %s' %record['best_model_dir'], flush=True)\n",
    "    best_valid_loss = 1e9\n",
    "    for it in range(params['n_iterations']):\n",
    "        print('Iterations %4d:\\t' %(it+1) , end='', flush=True)\n",
    "        # Train next batch\n",
    "        next_x1, next_x2, next_y, x1_len, x2_len = train_data_loader.next_batch(batch_size=params['batch_size'], pad_to_length=max_seq_len, pad_word=word2id['<pad>'], return_len=True)\n",
    "        batch_loss, batch_l1_loss, _ = sess.run([target_loss, l1_loss, train_step], \n",
    "                            feed_dict={context: next_x1, response: next_x2, target: next_y, \n",
    "                            keep_prob: params['keep_prob_train'], context_len: x1_len, response_len:x2_len}) \n",
    "        print('loss = %.5f / L1 = %.5f / elapsed time %.f' % (batch_loss, batch_l1_loss, time.time() - start_time), flush=True)\n",
    "        record['loss_train'].append( batch_loss.tolist() )\n",
    "        if it % 1000 == 0:\n",
    "            # Save the model if has smaller loss\n",
    "            current_valid_loss = get_valid_loss_accuracy(sess)\n",
    "            if current_valid_loss < best_valid_loss:\n",
    "                best_valid_loss = current_valid_loss\n",
    "                if not os.path.exists(record['best_model_dir']):\n",
    "                    os.makedirs(record['best_model_dir'])\n",
    "                save_path = saver.save(sess, record['best_model_dir']+'model.ckpt')\n",
    "                record['best_iter'] = it\n",
    "                print('Best model save in %d iteration' %it, flush=True)\n",
    "        if it % 100 == 0:\n",
    "            if not os.path.exists(record['newest_model_dir']):\n",
    "                os.makedirs(record['newest_model_dir'])\n",
    "            save_path = saver.save(sess, record['newest_model_dir']+'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Dump record file as .json\n",
    "if not os.path.exists(save_record_dir):\n",
    "    os.makedirs(save_record_dir)\n",
    "with open(save_record_dir+'%d.json' %params['n_iterations'], 'w') as f:\n",
    "    json.dump(record, f, indent=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "saver.restore(sess, 'models/two_encoders_3/newest/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load in sample and test\n",
    "sample = pd.read_csv('datas/sample_test_data.txt')\n",
    "sample_x1 = [[s for s in re.sub('[A-Z]:', '\\t', _).split('\\t') if len(s.strip())] for _ in sample.dialogue.values]\n",
    "sample_x2 = [[s for s in re.sub('[A-Z]:', '\\t', _).split('\\t') if len(s.strip())] for _ in sample.options.values]\n",
    "sample_y = sample.answer.values\n",
    "assert(np.sum([len(_)!=6 for _ in sample_x2]) == 0)\n",
    "sample_x1 = [[word for word in jieba.cut(' '.join(s)) if word != ' '] for s in sample_x1]\n",
    "sample_x2 = [[[word for word in jieba.cut(r) if word != ' '] for r in rs] for rs in sample_x2]\n",
    "\n",
    "\n",
    "test_datas = pd.read_csv('datas/AIFirstProblem.txt')\n",
    "test_x1 = [[s for s in re.sub('[A-Z]:', '\\t', _).split('\\t') if len(s.strip())] for _ in test_datas.dialogue.values]\n",
    "test_x2 = [[s for s in re.sub('[A-Z]:', '\\t', _).split('\\t') if len(s.strip())] for _ in test_datas.options.values]\n",
    "assert(np.sum([len(_)!=6 for _ in test_x2]) == 0)\n",
    "test_x1 = [[word for word in jieba.cut(' '.join(s)) if word != ' '] for s in test_x1]\n",
    "test_x2 = [[[word for word in jieba.cut(r) if word != ' '] for r in rs] for rs in test_x2]\n",
    "with open('datas/AIFirst_test_answer.txt', 'r') as f:\n",
    "    f.readline()\n",
    "    test_y = np.array([int(line.strip().split(',')[-1]) for line in f])\n",
    "    \n",
    "def word_lst_2_id_lst(lst, pad_to_len=-1):\n",
    "    pad_word_id = word2id['<pad>']\n",
    "    pad_len = max(len(lst), 0)\n",
    "    id_list = [word2id[lst[i]] if i<len(lst) and lst[i] in word2id else pad_word_id for i in range(pad_len)]\n",
    "    pad_len = pad_to_len - len(id_list)\n",
    "    if pad_len > 0:\n",
    "        id_list.extend([pad_word_id] * pad_len)\n",
    "    return id_list\n",
    "\n",
    "pad_to_length = -1\n",
    "\n",
    "sample_id1 = np.array([word_lst_2_id_lst(s, pad_to_length) for s in sample_x1])\n",
    "sample_id2 = np.array([[word_lst_2_id_lst(r, pad_to_length) for r in rs] for rs in sample_x2])\n",
    "test_id1 = np.array([word_lst_2_id_lst(s, pad_to_length) for s in test_x1])\n",
    "test_id2 = np.array([[word_lst_2_id_lst(r, pad_to_length) for r in rs] for rs in test_x2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Generate sample answer by $\\sigma(c^TMr)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "prob_score = []\n",
    "for q, rs in zip(sample_id1, sample_id2):\n",
    "    for r in rs:\n",
    "        now_score = sess.run(probs, {\n",
    "            context: [q],\n",
    "            response: [r],\n",
    "            keep_prob: params['keep_prob_valid'],\n",
    "            context_len:[len(q)],\n",
    "            response_len:[len(r)]})[0]\n",
    "        prob_score.append(now_score)\n",
    "prob_score = np.array(prob_score).reshape(-1, 6)\n",
    "my_ans = np.argmax(prob_score, axis=1)\n",
    "sample_correct = np.sum(my_ans == sample_y)\n",
    "print('sample correct %4d' % (sample_correct), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob_score = []\n",
    "for q, rs in zip(test_id1, test_id2):\n",
    "    for r in rs:\n",
    "        now_score = sess.run(probs, {\n",
    "            context: [q],\n",
    "            response: [r],\n",
    "            keep_prob: params['keep_prob_valid'],\n",
    "            context_len:[len(q)],\n",
    "            response_len:[len(r)]})[0]\n",
    "        prob_score.append(now_score)\n",
    "prob_score = np.array(prob_score).reshape(-1, 6)\n",
    "my_ans = np.argmax(prob_score, axis=1)\n",
    "test_correct = np.sum(my_ans == test_y)\n",
    "print('test correct %4d (%.4f)' % (test_correct, test_correct/(len(test_y))), flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Generate sample answer by $cosine\\_similarity(Mr, c)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def unitvec(vec):\n",
    "    l = np.linalg.norm(vec)\n",
    "    return vec / l if l != 0 else vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "qq = []\n",
    "rr = []\n",
    "for q, rs in zip(sample_id1, sample_id2):\n",
    "    q_response = sess.run(generated_response, {\n",
    "        context: [q],\n",
    "        keep_prob: params['keep_prob_valid'],\n",
    "        context_len: [len(q)]\n",
    "    })[0]\n",
    "    qq.append(q_response.reshape(-1))\n",
    "    for r in rs:\n",
    "        r_response = sess.run(encoding_response, {\n",
    "            response: [r],\n",
    "            keep_prob: params['keep_prob_valid'],\n",
    "            response_len: [len(r)]\n",
    "        })[0]\n",
    "        rr.append(r_response.reshape(-1))\n",
    "qq = np.array(qq)\n",
    "rr = np.array(rr).reshape(-1, 6, qq.shape[-1])\n",
    "qq.shape, rr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "state_cossim = []\n",
    "for q, rs in zip(qq, rr):\n",
    "    for r in rs:\n",
    "        state_cossim.append(np.dot(unitvec(q), unitvec(r)))\n",
    "state_cossim = np.array(state_cossim).reshape(-1, 6)\n",
    "my_ans = np.argmax(state_cossim, axis=1)\n",
    "sample_correct = np.sum(my_ans == sample_y)\n",
    "print('sample correct %4d' % (sample_correct), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "qq = []\n",
    "rr = []\n",
    "for q, rs in zip(test_id1, test_id2):\n",
    "    q_response = sess.run(generated_response, {\n",
    "        context: [q],\n",
    "        keep_prob: params['keep_prob_valid'],\n",
    "        context_len: [len(q)]\n",
    "    })[0]\n",
    "    qq.append(q_response.reshape(-1))\n",
    "    for r in rs:\n",
    "        r_response = sess.run(encoding_response, {\n",
    "            response: [r],\n",
    "            keep_prob: params['keep_prob_valid'],\n",
    "            response_len: [len(r)]\n",
    "        })[0]\n",
    "        rr.append(r_response.reshape(-1))\n",
    "qq = np.array(qq)\n",
    "rr = np.array(rr).reshape(-1, 6, qq.shape[-1])\n",
    "qq.shape, rr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "state_cossim = []\n",
    "for q, rs in zip(qq, rr):\n",
    "    for r in rs:\n",
    "        state_cossim.append(np.dot(unitvec(q), unitvec(r)))\n",
    "state_cossim = np.array(state_cossim).reshape(-1, 6)\n",
    "my_ans = np.argmax(state_cossim, axis=1)\n",
    "test_correct = np.sum(my_ans == test_y)\n",
    "print('test correct %4d (%.4f)' % (test_correct, test_correct/len(test_y)), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# now_emb = sess.run(embeddings_W)\n",
    "# with open('models/word2vec/two-encoder-3-newest.txt', 'w') as f:\n",
    "#     f.write('%d %d\\n' % now_emb.shape)\n",
    "#     for word, vec in zip(id2word, now_emb):\n",
    "#         f.write('%s %s\\n' % (word, ' '.join([str(f) for f in vec])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
