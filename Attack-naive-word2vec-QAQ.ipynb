{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# naive word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /Users/sunset/Talk2AI_Contest/datas/dict/dict.txt.big ...\n",
      "Loading model from cache /var/folders/43/l4vp_w_x4wb11mmy_bb1jrkc0000gn/T/jieba.u857f67a870683287981bc6f5b9493ffc.cache\n",
      "Loading model cost 1.944 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "from scipy import stats\n",
    "\n",
    "# Import & Init jieba\n",
    "import jieba\n",
    "jieba.set_dictionary('datas/dict/dict.txt.big')\n",
    "jieba.load_userdict('datas/dict/edu_dict.txt')\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "# Import util\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv('datas/sample_test_data.txt')\n",
    "x1 = [[s for s in re.sub('[A-Z]:', '\\t', _).split('\\t') if len(s.strip())] for _ in sample.dialogue.values]\n",
    "x2 = [[s for s in re.sub('[A-Z]:', '\\t', _).split('\\t') if len(s.strip())] for _ in sample.options.values]\n",
    "y = sample.answer.values\n",
    "assert(np.sum([len(_)!=6 for _ in x2]) == 0)\n",
    "\n",
    "test_datas = pd.read_csv('datas/AIFirstProblem.txt')\n",
    "test_x1 = [[s for s in re.sub('[A-Z]:', '\\t', _).split('\\t') if len(s.strip())] for _ in test_datas.dialogue.values]\n",
    "test_x2 = [[s for s in re.sub('[A-Z]:', '\\t', _).split('\\t') if len(s.strip())] for _ in test_datas.options.values]\n",
    "assert(np.sum([len(_)!=6 for _ in test_x2]) == 0)\n",
    "with open('datas/AIFirst_test_answer.txt', 'r') as f:\n",
    "    f.readline()\n",
    "    test_y = np.array([int(line.strip().split(',')[-1]) for line in f])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65865"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format('models/word2vec/dual-lstm-14-best.txt', binary=False)\n",
    "len(word_vectors.vocab)\n",
    "# word_vectors = KeyedVectors.load_word2vec_format('models/word2vec/vec200_win40_iter15_mincnt1.bin', binary=True)\n",
    "# len(word_vectors.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unk_cnt = 0\n",
    "for a, b in zip(x1, x2):\n",
    "    a_sentence = [word for s in a for word in jieba.cut(s) if word.strip() != '']\n",
    "    b_sentences = [[word for word in jieba.cut(s) if word.strip() != ''] for s in b]\n",
    "    \n",
    "    unk_cnt += len([w for w in a_sentence if w not in word_vectors.vocab])\n",
    "    unk_cnt += len([w for s in b_sentences for w in s if w not in word_vectors.vocab])\n",
    "unk_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Naive trial - centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def unitvec(vec):\n",
    "    l = np.linalg.norm(vec)\n",
    "    return vec / l if l != 0 else vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def centroid(sentence):\n",
    "    _ = [word_vectors.word_vec(word) for word in sentence if word in word_vectors.vocab]\n",
    "    return np.mean(_, axis=0) if len(_) > 0 else np.zeros(word_vectors.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def centroid_score(x1, x2):\n",
    "    cos_score = []\n",
    "    dot_score = []\n",
    "    for a, b in zip(x1, x2):\n",
    "        a_sentence = [word for s in a for word in jieba.cut(s) if word.strip() != '']\n",
    "        b_sentences = [[word for word in jieba.cut(s) if word.strip() != ''] for s in b]\n",
    "\n",
    "        a_center = centroid(a_sentence)\n",
    "        b_centers = [centroid(s) for s in b_sentences]\n",
    "\n",
    "        cos_score.append([np.dot(unitvec(a_center), unitvec(bc)) for bc in b_centers])\n",
    "    return np.array(cos_score).reshape(-1, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def attack_naive_centroid(x1, x2):\n",
    "    my_cos_ans = centroid_score(x1, x2)\n",
    "    return np.argmax(my_cos_ans, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               sample centroid: 0.6600\n",
      "               test   centroid: 0.6760\n"
     ]
    }
   ],
   "source": [
    "cos_ans = attack_naive_centroid(x1, x2)\n",
    "test_cos_ans = attack_naive_centroid(test_x1, test_x2)\n",
    "\n",
    "print('%30s: %.4f' % ('sample centroid', np.sum(cos_ans == y) / len(y)))\n",
    "print('%30s: %.4f' % ('test   centroid', np.sum(test_cos_ans == test_y) / len(test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def wvdis_score(x1, x2):\n",
    "    wvdis = []\n",
    "    for a, b in zip(x1, x2):\n",
    "        a_sentence = [word for s in a for word in jieba.cut(s) if word.strip() != '']\n",
    "        b_sentences = [[word for word in jieba.cut(s) if word.strip() != ''] for s in b]\n",
    "\n",
    "        wvdis.append([])\n",
    "        for r in b_sentences:\n",
    "            wvdis[-1].append(word_vectors.wmdistance(a_sentence, r))\n",
    "    wvdis = np.array(wvdis).reshape(-1, 6)\n",
    "    return np.array(wvdis).reshape(-1, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                sample wvm dis: 0.4800\n",
      "                test   wvm dis: 0.4980\n"
     ]
    }
   ],
   "source": [
    "wvdis = wvdis_score(x1, x2)\n",
    "test_wvdis = wvdis_score(test_x1, test_x2)\n",
    "wvdis_ans = np.argmin(wvdis, axis=1)\n",
    "test_wvdis_ans = np.argmin(test_wvdis, axis=1)\n",
    "print('%30s: %.4f' % ('sample wvm dis', np.sum(wvdis_ans == y) / len(y)))\n",
    "print('%30s: %.4f' % ('test   wvm dis', np.sum(test_wvdis_ans == test_y) / len(test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Output answer on testing datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('answer/exp/exp_14_best_naive.txt', 'w') as f:\n",
    "    f.write('id,ans\\n')\n",
    "    for i, ans in enumerate(test_cos_ans):\n",
    "        f.write('%d,%d\\n' % (i+1, ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
