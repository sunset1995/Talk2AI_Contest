{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# naive word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /Users/sunset/Talk2AI_Contest/datas/dict/dict.txt.big ...\n",
      "Loading model from cache /var/folders/43/l4vp_w_x4wb11mmy_bb1jrkc0000gn/T/jieba.u857f67a870683287981bc6f5b9493ffc.cache\n",
      "Loading model cost 1.957 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "\n",
    "# Import & Init jieba\n",
    "import jieba\n",
    "jieba.set_dictionary('datas/dict/dict.txt.big')\n",
    "jieba.load_userdict('datas/dict/edu_dict.txt')\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "# Import util\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv('datas/sample_test_data.txt')\n",
    "x1 = [[s for s in re.sub('[A-Z]:', '\\t', _).split('\\t') if len(s.strip())] for _ in sample.dialogue.values]\n",
    "x2 = [[s for s in re.sub('[A-Z]:', '\\t', _).split('\\t') if len(s.strip())] for _ in sample.options.values]\n",
    "y = sample.answer.values\n",
    "assert(np.sum([len(_)!=6 for _ in x2]) == 0)\n",
    "\n",
    "test_datas = pd.read_csv('datas/AIFirstProblem.txt')\n",
    "test_x1 = [[s for s in re.sub('[A-Z]:', '\\t', _).split('\\t') if len(s.strip())] for _ in test_datas.dialogue.values]\n",
    "test_x2 = [[s for s in re.sub('[A-Z]:', '\\t', _).split('\\t') if len(s.strip())] for _ in test_datas.options.values]\n",
    "assert(np.sum([len(_)!=6 for _ in test_x2]) == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65864"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word_vectors = KeyedVectors.load_word2vec_format('models/word2vec/fine-tuned.txt', binary=False)\n",
    "# len(word_vectors.vocab)\n",
    "word_vectors = KeyedVectors.load_word2vec_format('models/word2vec/vec200_win40_iter15_mincnt5.bin', binary=True)\n",
    "len(word_vectors.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2169132045"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count total occurance to estimate word probability\n",
    "total_word_cnt = np.sum([_.count for _ in word_vectors.vocab.values()])\n",
    "total_word_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unk_cnt = 0\n",
    "for a, b in zip(x1, x2):\n",
    "    a_sentence = [word for s in a for word in jieba.cut(s) if word.strip() != '']\n",
    "    b_sentences = [[word for word in jieba.cut(s) if word.strip() != ''] for s in b]\n",
    "    \n",
    "    unk_cnt += len([w for w in a_sentence if w not in word_vectors.vocab])\n",
    "    unk_cnt += len([w for s in b_sentences for w in s if w not in word_vectors.vocab])\n",
    "unk_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Naive trial - centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def centroid(sentence):\n",
    "    _ = [word_vectors.word_vec(word) for word in sentence if word in word_vectors.vocab]\n",
    "    return np.mean(_, axis=0) if len(_) > 0 else np.zeros(word_vectors.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def attack_naive_centroid(x1, x2):\n",
    "    my_cos_ans = []\n",
    "    my_dot_ans = []\n",
    "    for a, b in zip(x1, x2):\n",
    "        a_sentence = [word for s in a for word in jieba.cut(s) if word.strip() != '']\n",
    "        b_sentences = [[word for word in jieba.cut(s) if word.strip() != ''] for s in b]\n",
    "\n",
    "        a_center = centroid(a_sentence)\n",
    "        b_centers = [centroid(s) for s in b_sentences]\n",
    "\n",
    "        score = [spatial.distance.cosine(a_center, bc) for bc in b_centers]\n",
    "        my_cos_ans.append(np.argmin(score))\n",
    "        \n",
    "        score = [np.dot(a_center, bc) for bc in b_centers]\n",
    "        my_dot_ans.append(np.argmax(score))\n",
    "    return np.array(my_cos_ans), np.array(my_dot_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      centroid (cos):  30 /  50\n",
      "      centroid (dot):  27 /  50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py:505: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - np.dot(u, v) / (norm(u) * norm(v))\n"
     ]
    }
   ],
   "source": [
    "cos_ans, dot_ans = attack_naive_centroid(x1, x2)\n",
    "\n",
    "correct = np.sum(cos_ans == y)\n",
    "print('%20s: %3d / %3d' % ('centroid (cos)', correct, len(y)))\n",
    "\n",
    "correct = np.sum(dot_ans == y)\n",
    "print('%20s: %3d / %3d' % ('centroid (dot)', correct, len(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Naive trial - weighted centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def weighted_centroid(sentence, a=1e-4):\n",
    "    _ = [a / (a + word_vectors.vocab[word].count / total_word_cnt) * word_vectors.word_vec(word)\n",
    "            for word in sentence if word in word_vectors.vocab]\n",
    "    return np.mean(_, axis=0) if len(_) > 0 else np.zeros(word_vectors.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def attack_naive_weighted_centroid(x1, x2):\n",
    "    my_cos_ans = []\n",
    "    my_dot_ans = []\n",
    "    for a, b in zip(x1, x2):\n",
    "        a_sentence = [word for s in a for word in jieba.cut(s)]\n",
    "        b_sentences = [[word for word in jieba.cut(s)] for s in b]\n",
    "\n",
    "        a_center = weighted_centroid(a_sentence)\n",
    "        b_centers = [weighted_centroid(s) for s in b_sentences]\n",
    "\n",
    "        score = [spatial.distance.cosine(a_center, bc) for bc in b_centers]\n",
    "        my_cos_ans.append(np.argmin(score))\n",
    "        \n",
    "        score = [np.dot(a_center, bc) for bc in b_centers]\n",
    "        my_dot_ans.append(np.argmax(score))\n",
    "    return np.array(my_cos_ans), np.array(my_dot_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted centroid (cos):  30 /  50\n",
      "weighted centroid (dot):  27 /  50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py:505: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - np.dot(u, v) / (norm(u) * norm(v))\n"
     ]
    }
   ],
   "source": [
    "cos_ans, dot_ans = attack_naive_weighted_centroid(x1, x2)\n",
    "\n",
    "correct = np.sum(cos_ans == y)\n",
    "print('%20s: %3d / %3d' % ('weighted centroid (cos)', correct, len(y)))\n",
    "\n",
    "correct = np.sum(dot_ans == y)\n",
    "print('%20s: %3d / %3d' % ('weighted centroid (dot)', correct, len(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Naive trial - cosine similarity between two sets of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cos_sim(a_words_set, b_words_set):\n",
    "    a = [word for word in a_words_set if word in word_vectors.vocab]\n",
    "    b = [word for word in b_words_set if word in word_vectors.vocab]\n",
    "    if len(a) == 0 or len(b) == 0:\n",
    "        return 0\n",
    "    return word_vectors.n_similarity(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def attack_naive_cos_sim(x1, x2):\n",
    "    my_ans = []\n",
    "    for a, b in zip(x1, x2):\n",
    "        a_sentence = [word for s in a for word in jieba.cut(s)]\n",
    "        b_sentences = [[word for word in jieba.cut(s)] for s in b]\n",
    "\n",
    "        score = [cos_sim(a_sentence, bs) for bs in b_sentences]\n",
    "        my_ans.append(np.argmax(score))\n",
    "    return np.array(my_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      cos similarity:  31 /  50\n"
     ]
    }
   ],
   "source": [
    "cos_ans = attack_naive_cos_sim(x1, x2)\n",
    "correct = np.sum(cos_ans == y)\n",
    "print('%20s: %3d / %3d' % ('cos similarity', correct, len(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Try bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# QwQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Output answer on testing datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "my_test_ans = attack_naive_cos_sim(test_x1, test_x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('answer/attack-naive-word2vec-not-fine-tune.txt', 'w') as fo:\n",
    "    fo.write('id,ans\\n')\n",
    "    fo.write('\\n'.join(['%d,%s' % (i+1, ans) for i, ans in enumerate(my_test_ans)]))\n",
    "    fo.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
